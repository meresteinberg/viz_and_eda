---
title: "EDA"
output: github_document
date: "2024-10-03"
---

```{r setup, include=FALSE}
library(tidyverse)
library(haven)

```

adding in month=floor_date() function
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = case_match(
      id, 
      "USW00094728" ~ "CentralPark_NY", 
      "USW00022534" ~ "Molokai_HI",
      "USS0023B17S" ~ "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10,
    month= floor_date(date, unit= "month")) |>
  select(name, id, everything())
```

Let's make some plots 

```{r}
weather_df |> 
  ggplot(aes(x=prcp)) +
  geom_histogram()
```

showing real datapoints that had abnormally large rainfalls. do we care about outliers?
```{r}
weather_df |> 
  filter(prcp>1000)
```

```{r}
weather_df |> 
  filter(tmax>20, tmax<30) |> 
  ggplot(aes(x=tmin, y=tmax, color=name, shape=name)) +
  geom_point()
```

## group_by()

tells you how many groups of whatever variable you're putting in
```{r}
weather_df |> 
  group_by(name)
```

counting stuff

tells us how many obs we have and how many distinct months we have
```{r}
weather_df |> 
  group_by(name) |> 
  summarize(
      n_obs=n(),
      n_dist=n_distinct(month))
```

grouping by name and month
```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
      n_obs=n())
```

counting how many obs with count()
```{r}
weather_df |> 
  count(name)
```


## 2x2 

```{r}
weather_df |> 
  drop_na(tmax) |> 
  filter(name !="Molokai_HI") |> 
  mutate(
    cold = case_when(
      tmax <5 ~ "cold",
      tmax >=5 ~ "not_cold"
    )
  ) |> 
  group_by(name, cold) |> 
  summarize(count = n())
```
could pivot wider above to make a 2x2



janitor package tabyl() also produces a 2x2 (DO NOT USE table())
```{r}
weather_df |> 
  drop_na(tmax) |> 
  filter(name !="Molokai_HI") |> 
  mutate(
    cold = case_when(
      tmax <5 ~ "cold",
      tmax >=5 ~ "not_cold"
    )
  ) |> 
  janitor::tabyl(name, cold)
```

## general numeric summaries
lets try some other useful summaries

computing these summaries by name bc of group() function: can also do month, name and month, etc.
```{r}
weather_df |> 
  group_by(name) |> 
  summarize(
    mean_tmax= mean(tmax, na.rm=TRUE),
    median_tmin=median(tmin, na.rm=TRUE),
    sd_prcp= sd(prcp, na.rm=TRUE)
  )
```


summarize and then plot...
```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax= mean(tmax, na.rm=TRUE),
    median_tmin=median(tmin, na.rm=TRUE),
    sd_prcp= sd(prcp, na.rm=TRUE)
  ) |> 
  ggplot(aes(x = month, y = mean_tmax, color=name)) +
  geom_point() +
  geom_line()
```

format for readers

```{r}
weather_df |> 
  group_by(name) |> 
  summarize(
    mean_tmax= mean(tmax, na.rm=TRUE)
  ) |> 
  pivot_wider(
    names_from=name,
    values_from= mean_tmax
  ) |> 
  knitr::kable(digits= 3)
```


## grouped mutates

if we group first they are going to create means by that group
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(mean_tmax=mean(tmax, na.rm=TRUE),
         centered_tmax= tmax-mean_tmax) |> 
  ggplot(aes(x=date, y=centered_tmax, color=name)) +
  geom_point()
```


Find hottest/coldest days.

temp_rank<10 gives top 10 coldest days
temp_rank<4 with group will do top 3 coldest days for each group
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    temp_rank= min_rank(desc(tmax))
  ) |> 
  filter(temp_rank<4)


weather_df |> 
  group_by(name) |> 
  filter(min_rank(tmax) < 4) |> 
  arrange(tmax)
```
can also be done with filter in second chunk of code

lagged temp is giving us temp day before . temp change is giving us the temp change
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    lagged_tmax= lag(tmax), 
    temp_change= tmax-lagged_tmax
  ) |> 
  filter(min_rank(temp_change)<3)
```


```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    lagged_tmax= lag(tmax), 
    temp_change= tmax-lagged_tmax
  ) |> 
  summarize(
    sd_tmax_change = sd(temp_change, na.rm=TRUE)
  )
```

##Learning Assessment PULSE DATA ( file is messed up see Revisiting examples section )
```{r eval=FALSE} 
pulse_df=
  read_sas=("/data/public_pulse_data.sas7bdat") |> 
  janitor::clean_names() |> 
pivot_longer(
    bdi_score_bl:bdi_score_12m,
    names_to = "visit", 
    names_prefix = "bdi_score_",
    values_to = "bdi") |>
  select(id, visit, everything()) |>
  mutate(
    visit = replace(visit, visit == "bl", "00m"),
    visit = factor(visit, levels = str_c(c("00", "01", "06", "12"), "m"))) |>
  arrange(id, visit)

pulse_data |> 
  group_by(visit) |> 
  summarize(
    mean_bdi = mean(bdi, na.rm = TRUE),
    median_bdi = median(bdi, na.rm = TRUE)) |> 
  knitr::kable(digits = 3)
```

##Learning Assessment FAS DATA 

```{r}
litters_df=
  read_csv("data/FAS_litters.csv", na=c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(
    group, into= c("dose", "tx_day"), sep=3
  )

pups_df=
 read_csv("data/FAS_pups.csv") |>
  janitor::clean_names() |>
  mutate(sex = recode(sex, `1` = "male", `2` = "female")) 

fas_df=
  left_join(pups_df, litters_df, by="litter_number")
```

Compute table we care about

```{r}
fas_df |> 
  group_by(dose, tx_day) |> 
  drop_na(dose) |> 
  summarize(mean_pivot = mean(pd_pivot, na.rm = TRUE)) 
```

would want to pivot wider...
```{r}
fas_df |> 
  group_by(dose, tx_day) |> 
  drop_na(dose) |> 
  summarize(mean_pivot = mean(pd_pivot, na.rm = TRUE)) |> 
  pivot_wider(
    names_from = tx_day, 
    values_from = mean_pivot) |> 
  knitr::kable(digits = 3)
```

